{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18af6876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\chatbot_theme_identifier\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import google.generativeai as genai\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0886c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b33da111",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_reader = PyPDFLoader(\"example.pdf\")\n",
    "raw_docs = pdf_reader.load()\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True \n",
    ")\n",
    "chunks = text_splitter.split_documents(raw_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba671d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'OCR_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mOCR_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extract_text_scanned_doc\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'OCR_model'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3db078b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_11856\\502141384.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings()\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_11856\\502141384.py:1: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\chatbot_theme_identifier\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "db = FAISS.from_documents(documents=chunks, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1752b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"AIzaSyBH6hVJYI6XHlIdmeYcBn4UlPmUWL233aU\")\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "def get_context_with_sources(query, k=2):\n",
    "    \"\"\"Retrieve context with source metadata\"\"\"\n",
    "    docs = db.similarity_search_with_score(query, k=k)\n",
    "    return [\n",
    "        {\n",
    "            \"content\": doc.page_content,\n",
    "            \"page\": doc.metadata[\"page\"] + 1, \n",
    "            \"score\": score,\n",
    "            \"source\": doc.metadata[\"source\"]\n",
    "        }\n",
    "        for doc, score in docs\n",
    "    ]\n",
    "def get_context_with_sources_scanned_doc(query, k=2):\n",
    "    \"\"\"Retrieve context with source metadata\"\"\"\n",
    "    docs = db.similarity_search_with_score(query, k=k)\n",
    "    return [\n",
    "        {\n",
    "            \"content\": doc.page_content,\n",
    "            \"score\": score,\n",
    "        }\n",
    "        for doc, score in docs\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3d561eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(query, chat_history):\n",
    "    \"\"\"Enhanced prediction with source citations\"\"\"\n",
    "    context_data = get_context_with_sources_scanned_doc(query)\n",
    "    context_str = \"\\n\\n\".join(\n",
    "        f\"{ctx['content']}\"\n",
    "        for i, ctx in enumerate(context_data)\n",
    "    )\n",
    "    \n",
    "    prompt = f\"\"\"Answer using these verified sources. Cite page numbers using [Page X] notation.\n",
    "\n",
    "Sources:\n",
    "{context_str}\n",
    "\n",
    "Conversation history:\n",
    "{chat_history}\n",
    "\n",
    "Question:\n",
    "{query}\"\"\"\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text, context_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "158e1018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: According to Chikitsa Sthana, Avastika Chikitsa for Arsha includes the following:\n",
      "\n",
      "*   **Shushka Arsha (Vata Kaphaja) with Stambha, Shvayathu, Kandu, and Arti:** Vata Swedana [Page 705]\n",
      "*   **Shushka Arsha (Vata Kaphaja) with Stambha, Shvayathu, Kandu, and Arti:** Sechana with Nimbadi Jala [Page 705]\n",
      "*   **Shula in Shushka Arsha:** Avagahana (sitz bath) with Mulakadi Kwatha [Page 705]\n",
      "*   **Shula in Shushka Arsha:** Dhupana using Dhupana Yoga [Page 705, 38]\n",
      "*   **Shula in Shushka Arsha:** Lepa and Pradeha using Lepa Yoga [Page 705, 52-57]\n",
      "*   **Rakta Dushti in Arsha:** Rakta Mokshana using Jalauka, Suchi, or Siravyadha [Page 705, 60-61]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \" write on avastika chikista for arsha\"\n",
    "chat_history = []\n",
    "response_text, sources = model_prediction(query, chat_history)\n",
    "\n",
    "print(\"Answer:\", response_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58c38b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Economics deals with production, exchange, and consumption of commodities, focusing on how scarce resources can be used to increase wealth and human welfare [Page 1]. It addresses the problem of unlimited human wants and the scarcity of available resources [Page 1]. The word \"Economics\" comes from the Greek words \"oikos\" (a house) and \"nemein\" (to manage), meaning \\'managing a household\\' with limited funds [Page 1].\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b121be1b",
   "metadata": {},
   "source": [
    "this is for OCR model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb9c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Replace with your actual PDF path\n",
    "def extract_text_scanned_doc(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    text = \"\"\n",
    "    pdf_data = {}\n",
    "    for page_num in range(len(doc)):\n",
    "        # 2. Convert PDF page to image in memory\n",
    "        page = doc.load_page(page_num)\n",
    "        pix = page.get_pixmap()\n",
    "        img_bytes = pix.tobytes(\"png\")\n",
    "        \n",
    "        # 3. Convert to OpenCV format (CORRECTED)\n",
    "        pil_image = Image.open(io.BytesIO(img_bytes))\n",
    "        image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)  # Fix color conversion\n",
    "        # 4. Thresholding (improved parameters)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        _, im_bw = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        cv2.imwrite(f\"thresh{page_num}.jpg\", im_bw)\n",
    "        pdf_data[page_num+1]=pytesseract.image_to_string(im_bw, lang='eng')\n",
    "    return pdf_data      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07c83be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_text = extract_text_scanned_doc(\"text.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450c4c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = text_splitter.split_text(\"\".join(extract_text.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ead376ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Wrap each split text string into a Document object\n",
    "documents = [Document(page_content=chunk) for chunk in data]\n",
    "\n",
    "# Now create the FAISS vector store\n",
    "db = FAISS.from_documents(documents=documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cef55afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def is_scanned_pdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "        if text.strip():  # If there's any actual text\n",
    "            return False  # It's a typed (text-based) PDF\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15924cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PDF is typed (text-based).\n"
     ]
    }
   ],
   "source": [
    "file_path = \"example.pdf\"\n",
    "if is_scanned_pdf(file_path):\n",
    "    print(\"The PDF is scanned (image-based).\")\n",
    "else:\n",
    "    print(\"The PDF is typed (text-based).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073de4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
